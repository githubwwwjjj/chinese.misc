# chinese.misc
# 中文文本分析方便工具R包chinese.misc的中文说明
# 
# 本使用说明目前尚未完成，预计将于2017年4月以前完成。
# This Chinese manual has not been finished. It will be finished before Apr 2017.
# 
# ################
# 一、使用方法
# ################
# # 在Windows下的 R >=3.3.2 中，键入
# install.packages('chinese.misc')
# librarry(chinese.misc)
#
# ################
# 二、本R包的特点
# ################
# 编写本R包的目的主要是帮助使用者以相对自动和便捷的方式完成中文文本分析中一系列繁琐且易出错的工作；特别是帮助对文本分析的流程不太了解的初学者。
# 特点如下：
#  （1）能够仅用一行代码生成文档-词项矩阵，并在此过程中完成自动检测编码并读取文件、中文文本分词、定制性的文本清理、去除停用词等工作。
# （2）通过一些方法宽容用户的不正确输入，尝试纠正错误，或在报错时给出一般人能读得懂的报错信息。频频报错飘红什么的实在是太心烦了；错误少，大家心情都舒畅。
# （3）提供了若干在中文文本分析以外的任务中也能使用的函数，如类型判断、类型转化。
#
# ################
# 三、函数概览
# ################
# （一）用于自动读取中文文本、分词、生成语料或文档-词项矩阵：
# corp_or_dtm
# scancn
# seg_file
# dir_or_file
#
# （二）用于去除停用词或无意义词语：
# make_stoplist
# slim_text
#
# （三）用于txt/rtf和csv互转，方便那些偏好某种格式文件的童鞋：
# csv2txt
# txt2csv
#
# （四）类型判断、类型转化
# is_character_vector
# is_positive_integer
# as.character2
# as.numeric2
#
# （五）查看、统计词频
# output_dtm
# sort_tf
#
# （六）其它函数
# tf2doc
# m2doc
# match_pattern
#
# ————以下我将会分别介绍这些函数————
#
# ################
# 四、函数介绍
# ################
#
# 为进行讲解，首先需要提供几段文本做例子。
# 复制并运行以下代码（不用修改），会在你的工作目录里生成名为hehe的文件夹。如果这个文件夹之前已经在你电脑中存在了，会报错，请你自己改一个别的名。
# 程序会自动在这个文件夹里写入几个文件当样例。
#
# ###   ^_^ 从这行开始复制
#
# a_new='hehe'
# gwd=getwd()
# f=paste(gsub('/', '', gwd), a_new, sep='/')
# dir.create(f)
# dir.create(paste(f, 'f1', sep='/'))
# dir.create(paste(f, 'f2', sep='/'))
# x='以事件为选题的数据新闻最常出现在重大新闻事件的报道中。在这类事件中，数据报道可能是媒体精心制作的报道主体，也可能是媒体对事件的整个专题报道中的一个有机组成部分。可预见的重大新闻事件一般多指会议、活动、庆典或赛事，媒体可以把较为充足的时间投入到选题策划中。除了可预见的重大新闻事件以外，更多此类数据新闻的选题是突发新闻事件。近年来，越来越多的媒体将数据新闻运用于突发新闻事件的报道中，大量数据资源的整合和运用为此类新闻报道增添了更多科学性。'
# write.table(x, paste(f, 'f1/d1.txt', sep='/'), row.names=FALSE, col.names=FALSE, quote=FALSE, fileEncoding='UTF-8')
# x='人们对数据可视化的适用范围有着不同观点。例如，有专家认为数据可视化是可视化的一个子类目，主要处理统计图形、抽象的地理信息或概念型的空间数据。现代的主流观点将数据可视化看成传统的科学可视化和信息可视化的泛称，即处理对象可以是任意数据类型、任意数据特性，以及异构异质数据的组合。大数据时代的数据复杂性更高，如数据的流模式获取、非结构化、语义的多重性等。'
# write.table(x, paste(f, 'f1/d2.txt', sep='/'), row.names=FALSE, col.names=FALSE, quote=FALSE, fileEncoding='UTF-8')
# x='政治传播学是政治学与传播学的交叉学科，它是对政治传播现象的总结和政治传播规律的探索和运用，它包括政治传播的结构、功能、本质及技巧等方方面面。它的研究范围包括：政治传播行为，即政治传播的主体、客体及他们之间的相互关系体系；政治传播内容，即对政治的信息处理体系；政治传播途径，即政治符号和传播媒介体系；政治传播环境，即政治传播与相关社会现象；政治传播形态，即政治传播本体的形貌或表现体系。'
# write.table(x, paste(f, 'f2/d3.txt', sep='/'), row.names=FALSE, col.names=FALSE, quote=FALSE, fileEncoding='GB18030')
# x='改进社会治理方式。坚持系统治理，加强党委领导，发挥政府主导作用，鼓励和支持社会各方面参与，实现政府治理和社会自我调节、居民自治良性互动。坚持依法治理，加强法治保障，运用法治思维和法治方式化解社会矛盾。坚持综合治理，强化道德约束，规范社会行为，调节利益关系，协调社会关系，解决社会问题。坚持源头治理，标本兼治、重在治本，以网格化管理、社会化服务为方向，健全基层综合服务管理平台，及时反映和协调人民群众各方面各层次利益诉求。'
# write.table(x, paste(f, 'f2/d4.txt', sep='/'), row.names=FALSE, col.names=FALSE, quote=FALSE, fileEncoding='GB18030')
# x='所有这三种活动和它们的相应境况都与人存在的最一般状况相关：出生和死亡，诞生性和有死性。劳动不仅确保了个体生存，而且保证了类生命的延续。工作和它的产物——人造物品，为有死者生活的空虚无益和人寿的短促易逝赋予了一种持久长存的尺度。而行动，就它致力于政治体的创建和维护而言，为记忆，即为历史创造了条件。'
# write.table(x, paste(f, 'd5.txt', sep='/'), row.names=FALSE, col.names=FALSE, quote=FALSE, fileEncoding='UTF-8')
#
# ###   ^_^ 复制到这一行就OK啦
#
# （一）收集文件名、读文件
#  
# #现在你已经有了一个装了五个文件的文件夹f。
# #用dir可以收集这个文件里的文件名
# dir(f)
# #然而，dir只能下到文件夹的一层，怎样才能读到嵌套在子文件夹里的文件呢，这时候就要用chinese.misc包里的dir_or_file了。
# 这个函数允许你同时输入多个文件夹或文件的名称，两者混着往里放也没事；这些放进去的名字，既可以是绝对路径，也可以是相对路径，也可能是以~开头的路径。
# 无论如何，这个函数会判断文件是否存在（如果不存在则会报错），去掉重复的文件，然后把从小到大放了序的全部文件名收集起来。
# 假如你要分析的文件在不同的文件夹里，甚至有的在C盘，有的在F盘，有的在工作目录里，有的不在，有的是文件夹的名称，有的是文件的名称，那么就可以用这个函式来整理和收集你的文件名了。
# 
# dir_or_file (
#     ...,  #一个或多个代表文件夹/文件名
#     special = "" #代表模式的正则表达式或字符
# ) 
#
# 其中，...最好是字符或字符向量，但如果是一个由文件名组成的矩阵、列表什么的，也OK，反正程序会尝试进行转化。
# special代表你想要的文件的模式，默认是收集所有文件，但如果你只要要以txt结果的文件，就设special='txt$'。
#
# #举个栗子
# all_file=dir_or_file(f)
# all_file
# #看看是不是收集到了所有文件
# #如果你的文件名有重复，也没事，反正最后会去重的
# all_file=dir_or_file(f, f)
#
# 好的，现在我们已经收集好了文件名，接下来我们要读它们了。
# 我们要用chinese.misc包中名为scancn的函数。
# 它实际上就是一个scan函数，但是它可以自动检测文件编码，减少乱码的可能性，判断文件是否有实质内容，去除一些非法字符，并最后把文件拼接成单一一个字符。
# 这个函数永远不会输出0长度的对象或NA。因它如果你把它读出来的结果传递给其它函数，就是相对安全的。
# 当然，你用这个函数读英文文本也行，只是英文文本大多不会乱码，所以不需要特意用这个函数。
# 
# scancn(
#     x, #一个文件名
#     enc = "auto", #编码，默认为自动
#     read_2nd = TRUE #是否尝试读取两次
# )
# 
# 其中，enc是你的文件的编码。如果你的很多文件有不同的编码，或者你不知道编码，或者你已经被乱码搞得头大了，就不用改了，让它自动检测吧。
# read_2nd询问的是，是否要对被视为UTF-8文件但实际上并不是且无法正常读取的文件进行二次读取。默认为TRUE，基本上不用您改。
#
# 写个循环，依次读取五个文件，看能不能读出来。
# for (each in all_file){
#     message(each)
#     text=scancn(each)
#     print(text)
# }
# #都打印在你的屏幕上了吧！



